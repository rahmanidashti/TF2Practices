{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 - TF2Practice - Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPK0INwmwpp9glF96bJJoLW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahmanidashti/TF2Practices/blob/main/01_TF2Practice_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnNobMqNQd-_"
      },
      "source": [
        "# Optimization in TF.2\n",
        "\n",
        "`min(f(x)) w.r.t constraints`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms87pai4RUhY"
      },
      "source": [
        "## Learning procedure in TF.2\n",
        "1. Defining learning model\n",
        "2. Defning loss function\n",
        "3. Loss function minimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48A6161mSk9r"
      },
      "source": [
        "### Example\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN_Et_zyTRpK"
      },
      "source": [
        "#### Definig learning model\n",
        "\n",
        "In this example, we are going to create a `linear regression` model which is one of the fundamental supervised learning algorithms. In contrast to the classification problem in which the outputs are labels and **discrete**, the outputs in regression are continuous and it is about the prediction of quantity, not labels.\n",
        "\n",
        "Linear regression:\n",
        "$f(x_i) = w^T . x_i + b$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NanU-f4PrKJ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "kvfYGe6iQTEi",
        "outputId": "e5e36088-bed5-45ef-e11d-60e7d515babb"
      },
      "source": [
        "# Dataset: random data\n",
        "\n",
        "# The linspace(start, stop, num) function returns evenly spaced numbers over a specified interval [start, stop].\n",
        "x = np.linspace(0, 4, 120)\n",
        "\n",
        "# create a data around the line 2*x+0.9\n",
        "y = 2 * x + 0.9 + np.random.randn(x.shape[0]) + 0.3\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIy3tBc-krnE"
      },
      "source": [
        "class Linearregmodel:\n",
        "  # the constructor method sets W and b\n",
        "  def __init__(self):\n",
        "    self.Weight = tf.Variable(5.0)\n",
        "    self.Bias = tf.Variable(6.0)\n",
        "  # Using __call__ method we can call the class like a function\n",
        "  def __call__(self, x):\n",
        "    return self.Weight * x + self.Bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpSIsI7VraVT"
      },
      "source": [
        "#### Defining loss function\n",
        "\n",
        "We need to define a loss function to optimize the model's parameter. Here, we consdier Mean Square Error (MSE) which is: $\\frac{1}{n}\\sum_{i=1}^{n}(y_i^t-y_i^p)^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RbtFYzZrANt"
      },
      "source": [
        "def loss(actual_values, predicted_values):\n",
        "  # square: to the power of 2\n",
        "  # reduce_mean: mean of values\n",
        "  return tf.reduce_mean(tf.square(actual_values - predicted_values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZtPeBYYt2mD"
      },
      "source": [
        "#### Loss function minimization\n",
        "\n",
        "Gradient descent: $x_{n+1}=x_n - \\eta\\frac{\\partial f}{\\partial x}$ where $\\eta$ is learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCpPQdaqtbwv"
      },
      "source": [
        "def train(linear_model, x, y, learning_rate=0.12):\n",
        "  with tf.GradientTape() as t:\n",
        "    current_loss = loss(actual_values=y, predicted_values=linear_model(x))\n",
        "\n",
        "  ''' we need to optimize our model parametrs which in this model wight and \n",
        "  bias are our model parametrs. So, we have to compute the gradient (derivations) \n",
        "  of our loss function into model parametrs.\n",
        "  '''\n",
        "\n",
        "  lr_weight, lr_bias = t.gradient(current_loss, [linear_model.Weight, linear_model.Bias])\n",
        "\n",
        "  # update the weight and biase based on the new valeus of gradients\n",
        "  linear_model.Weight.assign_sub(learning_rate * lr_weight)\n",
        "  linear_model.Bias.assign_sub(learning_rate * lr_bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbV0W-k2x6f4",
        "outputId": "7cb7f63f-d2c0-4959-92c3-e6c0cfccbafe"
      },
      "source": [
        "linear_model = Linearregmodel()\n",
        "epochs = 100\n",
        "for epoch_count in range(epochs):\n",
        "  real_loss = loss(actual_values=y, predicted_values=linear_model(x))\n",
        "  train(linear_model, x, y, learning_rate=0.12)\n",
        "  print(f\"Epoch count = {epoch_count}, Loss value = {real_loss.numpy()}\")\n",
        "\n",
        "print(f\"linear_model.Weight: {linear_model.Weight.numpy()}\")\n",
        "print(f\"linear_model.Bias: {linear_model.Bias.numpy()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch count = 0, Loss value = 126.83720397949219\n",
            "Epoch count = 1, Loss value = 30.425928115844727\n",
            "Epoch count = 2, Loss value = 8.766112327575684\n",
            "Epoch count = 3, Loss value = 3.7991867065429688\n",
            "Epoch count = 4, Loss value = 2.570418357849121\n",
            "Epoch count = 5, Loss value = 2.1881070137023926\n",
            "Epoch count = 6, Loss value = 2.005814552307129\n",
            "Epoch count = 7, Loss value = 1.8781630992889404\n",
            "Epoch count = 8, Loss value = 1.7716845273971558\n",
            "Epoch count = 9, Loss value = 1.6779841184616089\n",
            "Epoch count = 10, Loss value = 1.5943572521209717\n",
            "Epoch count = 11, Loss value = 1.5194549560546875\n",
            "Epoch count = 12, Loss value = 1.4523069858551025\n",
            "Epoch count = 13, Loss value = 1.3920975923538208\n",
            "Epoch count = 14, Loss value = 1.338106393814087\n",
            "Epoch count = 15, Loss value = 1.2896908521652222\n",
            "Epoch count = 16, Loss value = 1.2462750673294067\n",
            "Epoch count = 17, Loss value = 1.207342505455017\n",
            "Epoch count = 18, Loss value = 1.1724302768707275\n",
            "Epoch count = 19, Loss value = 1.1411231756210327\n",
            "Epoch count = 20, Loss value = 1.113049030303955\n",
            "Epoch count = 21, Loss value = 1.0878740549087524\n",
            "Epoch count = 22, Loss value = 1.0652985572814941\n",
            "Epoch count = 23, Loss value = 1.0450541973114014\n",
            "Epoch count = 24, Loss value = 1.0269006490707397\n",
            "Epoch count = 25, Loss value = 1.0106215476989746\n",
            "Epoch count = 26, Loss value = 0.9960235357284546\n",
            "Epoch count = 27, Loss value = 0.9829330444335938\n",
            "Epoch count = 28, Loss value = 0.9711942076683044\n",
            "Epoch count = 29, Loss value = 0.960667610168457\n",
            "Epoch count = 30, Loss value = 0.9512280225753784\n",
            "Epoch count = 31, Loss value = 0.9427631497383118\n",
            "Epoch count = 32, Loss value = 0.9351724982261658\n",
            "Epoch count = 33, Loss value = 0.9283657073974609\n",
            "Epoch count = 34, Loss value = 0.922261655330658\n",
            "Epoch count = 35, Loss value = 0.9167879819869995\n",
            "Epoch count = 36, Loss value = 0.9118795990943909\n",
            "Epoch count = 37, Loss value = 0.9074780344963074\n",
            "Epoch count = 38, Loss value = 0.903531014919281\n",
            "Epoch count = 39, Loss value = 0.8999916315078735\n",
            "Epoch count = 40, Loss value = 0.8968175649642944\n",
            "Epoch count = 41, Loss value = 0.8939714431762695\n",
            "Epoch count = 42, Loss value = 0.8914192318916321\n",
            "Epoch count = 43, Loss value = 0.8891304135322571\n",
            "Epoch count = 44, Loss value = 0.887078046798706\n",
            "Epoch count = 45, Loss value = 0.8852376341819763\n",
            "Epoch count = 46, Loss value = 0.8835872411727905\n",
            "Epoch count = 47, Loss value = 0.8821073174476624\n",
            "Epoch count = 48, Loss value = 0.8807801604270935\n",
            "Epoch count = 49, Loss value = 0.8795900940895081\n",
            "Epoch count = 50, Loss value = 0.8785228729248047\n",
            "Epoch count = 51, Loss value = 0.8775658011436462\n",
            "Epoch count = 52, Loss value = 0.8767077326774597\n",
            "Epoch count = 53, Loss value = 0.8759381771087646\n",
            "Epoch count = 54, Loss value = 0.8752480745315552\n",
            "Epoch count = 55, Loss value = 0.8746291995048523\n",
            "Epoch count = 56, Loss value = 0.8740742802619934\n",
            "Epoch count = 57, Loss value = 0.8735767006874084\n",
            "Epoch count = 58, Loss value = 0.8731304407119751\n",
            "Epoch count = 59, Loss value = 0.8727303147315979\n",
            "Epoch count = 60, Loss value = 0.8723714351654053\n",
            "Epoch count = 61, Loss value = 0.8720496892929077\n",
            "Epoch count = 62, Loss value = 0.8717612028121948\n",
            "Epoch count = 63, Loss value = 0.8715023398399353\n",
            "Epoch count = 64, Loss value = 0.8712703585624695\n",
            "Epoch count = 65, Loss value = 0.8710622191429138\n",
            "Epoch count = 66, Loss value = 0.8708757162094116\n",
            "Epoch count = 67, Loss value = 0.8707083463668823\n",
            "Epoch count = 68, Loss value = 0.8705583214759827\n",
            "Epoch count = 69, Loss value = 0.8704237341880798\n",
            "Epoch count = 70, Loss value = 0.8703030943870544\n",
            "Epoch count = 71, Loss value = 0.8701948523521423\n",
            "Epoch count = 72, Loss value = 0.8700979351997375\n",
            "Epoch count = 73, Loss value = 0.8700109720230103\n",
            "Epoch count = 74, Loss value = 0.8699329495429993\n",
            "Epoch count = 75, Loss value = 0.869862973690033\n",
            "Epoch count = 76, Loss value = 0.8698002099990845\n",
            "Epoch count = 77, Loss value = 0.8697440028190613\n",
            "Epoch count = 78, Loss value = 0.8696935176849365\n",
            "Epoch count = 79, Loss value = 0.8696482181549072\n",
            "Epoch count = 80, Loss value = 0.86960768699646\n",
            "Epoch count = 81, Loss value = 0.869571328163147\n",
            "Epoch count = 82, Loss value = 0.8695387244224548\n",
            "Epoch count = 83, Loss value = 0.8695093989372253\n",
            "Epoch count = 84, Loss value = 0.8694831728935242\n",
            "Epoch count = 85, Loss value = 0.8694596886634827\n",
            "Epoch count = 86, Loss value = 0.8694385290145874\n",
            "Epoch count = 87, Loss value = 0.8694196939468384\n",
            "Epoch count = 88, Loss value = 0.8694026470184326\n",
            "Epoch count = 89, Loss value = 0.8693874478340149\n",
            "Epoch count = 90, Loss value = 0.8693738579750061\n",
            "Epoch count = 91, Loss value = 0.8693617582321167\n",
            "Epoch count = 92, Loss value = 0.8693507313728333\n",
            "Epoch count = 93, Loss value = 0.8693407773971558\n",
            "Epoch count = 94, Loss value = 0.8693320155143738\n",
            "Epoch count = 95, Loss value = 0.8693240284919739\n",
            "Epoch count = 96, Loss value = 0.8693169355392456\n",
            "Epoch count = 97, Loss value = 0.8693106174468994\n",
            "Epoch count = 98, Loss value = 0.8693050146102905\n",
            "Epoch count = 99, Loss value = 0.8692998290061951\n",
            "linear_model.Weight: 1.9427632093429565\n",
            "linear_model.Bias: 1.4712718725204468\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}