{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02 - TF2Practice - Neural Network.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPb49liweH8erQZhoC8J2G/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahmanidashti/TF2Practices/blob/main/02_TF2Practice_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivDo1QzNMPY-"
      },
      "source": [
        "# Neural Network\n",
        "\n",
        "Structure: Input layer, Hidden layers, Output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJYChTrCNG_p"
      },
      "source": [
        "## Learning in Neural Netowrks\n",
        "\n",
        "In neural networks, similar to the other machine learning models such as linear regression, learning includes the optimization of network parameters so that loss function has the minimum value. To this end, we apply a backpropagation approach to compute the errors and propagate them to the previous layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_kf4Syef_kF"
      },
      "source": [
        "## Data, Model, Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0ur2-T_Trvo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsFYl2sNgDmj"
      },
      "source": [
        "### Data\n",
        "Using the fashion MNIST dataset from tf.keras.datasets, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W2mH-D6Ovct",
        "outputId": "309010aa-cd35-4145-da8f-3bc6f570d86d"
      },
      "source": [
        "# load the Fashion MNIST dataset from keras datasets\n",
        "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# sample number of train and test data\n",
        "print(f\"The train data size is {train_data.shape}\")\n",
        "print(f\"The test data size is {test_data.shape}\")\n",
        "\n",
        "# normalizaitino - between zero to one (each pixcel is between 0 to 255)\n",
        "train_data = train_data / 255.0\n",
        "test_data = test_data / 255.0\n",
        "\n",
        "input_data_shape = (28, 28)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The train data size is (60000, 28, 28)\n",
            "The test data size is (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTn6YsqFgOf_"
      },
      "source": [
        "### Model\n",
        "A sequential neural network which includes layers like a stack."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_Whoi8sekY9",
        "outputId": "0d0a670f-3fce-4d82-d9d8-ef6658535a73"
      },
      "source": [
        "# a sequantial neural network model\n",
        "nn_model = tf.keras.models.Sequential(name=\"simple_network_architecture\")\n",
        "\n",
        "# an flatten input layer convert a matrix of 28*28 into a vector of size 748\n",
        "nn_model.add(tf.keras.layers.Flatten(input_shape=input_data_shape))\n",
        "\n",
        "# a hidden layer which includes 32 neurons and relu activation\n",
        "# relu pass everything bigger than 0 otherwise pass zero\n",
        "\n",
        "nn_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "\n",
        "# as we have 10 labels so this is a mulitlable classification problem\n",
        "# softmax gives a probability for each lable in multi lable classification\n",
        "nn_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "nn_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"simple_network_architecture\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63j3vrCFf2oL"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgHeb9YOPQRs",
        "outputId": "09537903-f2db-462c-8b98-dc3fec9a4eac"
      },
      "source": [
        "''' Model configuration, and training and tsting. \n",
        "Configuration for complie can be loaded by using keras as well, \n",
        "for example, as for optimizer: tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "'''\n",
        "\n",
        "nn_model.compile(optimizer='adam', \n",
        "                 loss='sparse_categorical_crossentropy', \n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "nn_model.fit(x=train_data, y=train_labels, batch_size=128, epochs=10)\n",
        "\n",
        "test_loss, test_accuracy = nn_model.evaluate(x=test_data, y=test_labels)\n",
        "\n",
        "print(\"The accuracy on test data is {}\".format(round(float(test_accuracy), 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.9241 - accuracy: 0.7019\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4686 - accuracy: 0.8396\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4251 - accuracy: 0.8523\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3906 - accuracy: 0.8651\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3816 - accuracy: 0.8670\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3709 - accuracy: 0.8682\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3579 - accuracy: 0.8749\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3497 - accuracy: 0.8759\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3431 - accuracy: 0.8803\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8824\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3894 - accuracy: 0.8668\n",
            "The accuracy on test data is 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}